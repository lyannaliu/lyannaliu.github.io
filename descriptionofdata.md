---
layout: page
permalink: /descriptionofdata/index.html
title: Description of Data
---

# Description of Data

* [1. Summary](#1)
* [2. LastFM](#2)
    * [2.1 Data Source](#2.1)
    * [2.2 Description of the Raw Data](#2.2)
    * [2.3 Exploratory Data Analysis](#2.3)
* [3. Million Playlist](#3)
    * [3.1 Data Source](#3.1)
    * [3.2 Description of the Raw Data](#3.2)
    * [3.3 Exploratory Data Analysis](#3.3)

<h2 id="1">1. Summary</h2>
We used Last.FM Data Set and Million Playlist Data Set as our two data sets.

<h2 id="2">2. LastFM</h2>
<h3 id="2.1">2.1 Data Source</h3>
We obtained the data from the Last.fm Dataset on the Million Song Dataset: https://labrosa.ee.columbia.edu/millionsong/lastfm. 

<h3 id="2.2">2.2 Description of the Raw Data</h3>
The Last.fm data set contains:

  - song tags (eg genres and/or official playlists, Bay Area top 100 or Hip Hop) and song/track similarity for all of the tracks in the Million Song Dataset
  - SQLite databases that can be parsed
  - Numerical Variables: Artist Hotness; Artist Familiarity; Duration; Similarity
  - Categorical Variables: Track ID; Artist Name; Same Album; Tags; Year of release

<h3 id="2.3">2.3 Exploratory Data Analysis</h3>
Code used to process/clean data
Code used to create visualizations
Code used to compare with Million Playlist data

<h2 id="3">3. Million Playlist</h2>

<h3 id="3.1">3.1 Data Source</h3>
We obtained data from: https://drive.google.com/file/d/1vvKVox1_MNezGJA7PCt_ZplQDqoVYA--/view
This data distribution is for our Summer CS109A project purposes ONLY and MUST NOT be distributed for any other uses and for any other reasons during the course and after the course's conclusion.

<h3 id="3.2">3.2 Description of the Raw Data</h3>
The Million Playlist data set contains:

  - one million playlists generated by Spotify users from January 2010 to October 2017 (in JSON format)
  - Attributes include: 
  - Playlist name
  - number of tracks included
  - number of followers 
  - Each song includes artist name, track name, duration (ms), album name, along with their respective URIs
  - Numerical Variables are calculated dynamically depending on the target song and include the following (further detailed in the EDA): 
  - Related song frequency
  - Related artist frequency
  - Related album frequency
  - Total song frequency
  - Total artist frequency
  - Total album frequency
  
Include one dictionary/df to illustrate - Haley
Issues with the data?
Steps taken to clean
Code used to clean data
<h3 id="3.3">3.3 Exploratory Data Analysis</h3>

The first step to analyzing the Million Playlist Data was to decide the data structure that would best suit the needs of both the Last.FM Model and Million Playlist Model. The biggest issue with the playlist data was ensuring that tracks could be identified as unique while keeping the amount of loaded information to a minimum (to reduce memory costs).

There were several instances of tracks with the same song name, and several instances of tracks with the same song and artist but different albums. Therefore, we made the following decisions:

- Remastered/Remixes of the same song performed by the same artists are considered different tracks.
- The same song performed by different artists are considered different tracks.
- The same songs performed by the same artist in different albums are considered different tracks.

The most obvious way to store a track was as a `namedtuple` with three properties - song, artist, and album.

```python
Track = namedtuple("Track", ["song", "artist", "album"])
```

Using this template, we loaded each playlist as a list of Track `namedtuple`s, and the entire list of playlists as a list of lists.

```python
def randomly_load_files():
    all_playlists = []
    all_files = glob.glob("mpd.v1/data/100000/*.json")
    for file in all_files:
        with open(file) as f:
            data = json.load(f)
            all_playlists.extend([[Track(song=track['track_name'], artist=track['artist_name'], 
                album=track['album_name']) for track in playlist['tracks']] for playlist in data['playlists']])
    return all_playlists
```

Another challenge we faced was memory restrictions. Loading the full list of 1,000,000 playlists wasn't feasible, so we trimmed the data down to just 100,000 playlists. Out of these 100,000 playlists, 90% were designated train and 10% were designated test. After loading the data, we achieved this random split using `sklearn`'s `train_test_split` method.

```python
all_playlists = randomly_load_files()
detailed_train_playlists, detailed_test_playlists = train_test_split(all_playlists, train_size=.9)
```

The training and test sets were pickled and used for both the Last.FM and Million Playlist models. This handled the issue of creating train and test sets of data.

```python
with open('detailed_train_playlists.pkl', 'wb') as f:
    pickle.dump(detailed_train_playlists, f)

with open('detailed_test_playlists.pkl', 'wb') as f:
    pickle.dump(detailed_test_playlists, f)
```

The next question we needed to answer was how to turn completely categorical data with too many variables to 1-hot encode into preferably numerical data that could be ingested by a model.

We began by exploring the concept of calculating total counts of songs, artists, and albums from the training set as potential attributes for a track.

```python
# get counts of all unique songs, artists, and albums
def get_unique(playlist_list):
    totalArtists = Counter()
    totalAlbums = Counter()
    details = Counter()
    for playlist in playlist_list:
        for track in playlist:
            totalArtists[track.artist] += 1
            totalAlbums[track.album] += 1
            details[track] += 1
    return (totalArtists, totalAlbums, details)

totalArtistCount, totalAlbumCount, songDetails = get_unique(detailed_train_playlists)
```

The above function returns three `Counter`s (that function similarly to a dictionary) that contain the number of times each unique track, artist, and album appears across all training playlists.

```python
# Count of tracks
songDetails.most_common()
[(Track(song='HUMBLE.', artist='Kendrick Lamar', album='DAMN.'), 3984),
 (Track(song='One Dance', artist='Drake', album='Views'), 3844),
 (Track(song='Closer', artist='The Chainsmokers', album='Closer'), 3730),
 (Track(song='Broccoli (feat. Lil Yachty)', artist='DRAM', album='Big Baby DRAM'),
  3679),
 (Track(song='Congratulations', artist='Post Malone', album='Stoney'), 3538),
 (Track(song='Caroline', artist='Aminé', album='Good For You'), 3172),
 (Track(song='iSpy (feat. Lil Yachty)', artist='KYLE', album='iSpy (feat. Lil Yachty)'),
  3135),
 (Track(song='Location', artist='Khalid', album='American Teen'), 3103),
 (Track(song='XO TOUR Llif3', artist='Lil Uzi Vert', album='Luv Is Rage 2'),
  3100),
 (Track(song='Bad and Boujee (feat. Lil Uzi Vert)', artist='Migos', album='Culture'),
  3051),
 (Track(song='No Role Modelz', artist='J. Cole', album='2014 Forest Hills Drive'),
  2899),
 (Track(song='Bounce Back', artist='Big Sean', album='I Decided.'), 2860),
 (Track(song='Ignition - Remix', artist='R. Kelly', album='Chocolate Factory'),
  2860),
  ...

# Count of artists
totalArtistCount.most_common()

[('Drake', 74492),
 ('Kanye West', 37094),
 ('Kendrick Lamar', 31078),
 ('Rihanna', 30070),
 ('The Weeknd', 28218),
 ('Eminem', 25941),
 ('Ed Sheeran', 24748),
 ('Future', 22572),
 ('J. Cole', 21718),
 ('Justin Bieber', 21235),
 ('Beyoncé', 21235),
 ('The Chainsmokers', 19982),
 ('Chris Brown', 18625),
 ('Luke Bryan', 18580),
 ('Twenty One Pilots', 17924),
 ('Calvin Harris', 17851),
 ('Lil Uzi Vert', 17612),
 ('Post Malone', 17240),
 ...

 # Count of albums
 [('Views', 18436),
 ('Stoney', 13837),
 ('Greatest Hits', 13504),
 ('More Life', 12396),
 ('DAMN.', 12341),
 ('Beauty Behind The Madness', 12287),
 ('Coloring Book', 11868),
 ('American Teen', 10906),
 ('Culture', 10712),
 ('The Life Of Pablo', 10214),
 ('Purpose', 10114),
 ('2014 Forest Hills Drive', 9766),
 ('Starboy', 9566),
 ('Blurryface', 9488),
 ('ANTI', 9350),
 ('÷', 9190),
 ('Original Album Classics', 9185),
 ('x', 8885),
 ('Montevallo', 8815)
 ...
 ```

 Next, we were interested in visualizing any trends for these counts by plotting the calculated frequencies.

```python
# Plot total track, artist, and album counts
count_types = [songDetails, totalArtistCount, totalAlbumCount]
count_type_names = ['Tracks', 'Artists', 'Albums']

fig, ax = plt.subplots(nrows=3, ncols=1)
fig.set_size_inches(10, 15)
fig.suptitle('Total Counts of Tracks, Artists, and Albums', fontsize=20, y=0.95)

for count_type, count_type_name, i in zip(count_types, count_type_names, range(3)):
    ax[i].scatter(range(len(count_type)), count_type.values(), label=count_type_name)
    ax[i].set_xlabel('Indexes')
    ax[i].set_ylabel('Total count')
    ax[i].set_title('Total counts of {}'.format(count_type_name))
```

![Total Counts](/images/total_counts.png)

By doing so we discovered that all three follow a similar Pareto distribution. Colinearity became a concern, so we selected ten tracks and compared the trend of the total song count, artist count, and album counts of each song.

```python
# Plot subset of counts
from matplotlib.lines import Line2D

colors = ['blueviolet', 'chartreuse', 'chocolate', 'coral', 'cornflowerblue', 'darkorchid', 'fuchsia',
         'indianred', 'mediumblue', 'lightpink']
markers = [Line2D([], [], marker='.', markersize=10, label='Song Count'),
           Line2D([], [], marker='x', markersize=10, label='Artist Count'), 
           Line2D([], [], marker='o', markersize=10, label='Album Count')]

fig, ax = plt.subplots()
fig.set_size_inches(10, 5)
fig.suptitle('Total Counts of a Subset of Tracks, Artists, and Albums', fontsize=20, y=0.95)

for i in range(10):
    ax.scatter(i, songDetails[detailed_train_playlists[0][i]], marker='.', color=colors[i])
    ax.scatter(i, totalArtistCount[detailed_train_playlists[0][i].artist], marker='x', color=colors[i])
    ax.scatter(i, totalAlbumCount[detailed_train_playlists[0][i].album], marker='o', color=colors[i])

ax.set_xlabel('Indexes')
ax.set_ylabel('Total count')
ax.legend(handles=markers)
```

![Count Comparison](/images/count_comparison.png)

The plot shows that songs with high counts do not necessarily have artists and albums with high counts. The same holds true for the relationship between artists and albums to songs. Therefore, even though there is some visible colinearity, we determined that the frequency counts were not perfectly colinear and could potentially be significant as separate predictors.
